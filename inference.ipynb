{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from rich.pretty import pprint\n",
    "\n",
    "from src.data.data_pipeline import data_pipeline\n",
    "from src.factories import (\n",
    "    get_callbacks,\n",
    "    get_dataloaders,\n",
    "    get_datasets,\n",
    "    get_lookups,\n",
    "    get_lr_scheduler,\n",
    "    get_metric_collections,\n",
    "    get_model,\n",
    "    get_optimizer,\n",
    "    get_text_encoder,\n",
    "    get_transform,\n",
    ")\n",
    "from src.trainer.trainer import Trainer\n",
    "from src.utils.seed import set_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters for inference ###\n",
    "model_to_load = 'mimic_axa_cpt_hierarchical'\n",
    "k=5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makes all necessary imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set directory \n",
    "dir_all_models = Path('files')\n",
    "model_checkpoints = dir_all_models/model_to_load\n",
    "\n",
    "#load config file\n",
    "cfg = OmegaConf.load(model_checkpoints/'config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Device: cpu'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Device: cpu'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'CUDA_VISIBLE_DEVICES: 0'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'CUDA_VISIBLE_DEVICES: 0'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if CUDA_VISIBLE_DEVICES is set\n",
    "if \"CUDA_VISIBLE_DEVICES\" not in os.environ:\n",
    "    if cfg.gpu != -1 and cfg.gpu is not None and cfg.gpu != \"\":\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = (\n",
    "            \",\".join([str(gpu) for gpu in cfg.gpu])\n",
    "            if isinstance(cfg.gpu, list)\n",
    "            else str(cfg.gpu)\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pprint(f\"Device: {device}\")\n",
    "pprint(f\"CUDA_VISIBLE_DEVICES: {os.environ['CUDA_VISIBLE_DEVICES']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at RoBERTa-base-PM-M3-Voc/RoBERTa-base-PM-M3-Voc-hf were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_pipeline(config=cfg.data)\n",
    "\n",
    "text_encoder = get_text_encoder(\n",
    "    config=cfg.text_encoder, data_dir=cfg.data.dir, texts=data.get_train_documents\n",
    ") #not needed\n",
    "label_transform = get_transform(\n",
    "    config=cfg.label_transform,\n",
    "    targets=data.all_targets,\n",
    "    load_transform_path=cfg.load_model,\n",
    ") #not needed\n",
    "text_transform = get_transform(\n",
    "    config=cfg.text_transform,\n",
    "    texts=data.get_train_documents,\n",
    "    text_encoder=text_encoder,\n",
    "    load_transform_path=cfg.load_model,\n",
    ")\n",
    "\n",
    "lookups = get_lookups(\n",
    "    config=cfg.lookup,\n",
    "    data=data,\n",
    "    label_transform=label_transform,\n",
    "    text_transform=text_transform,\n",
    ")\n",
    "\n",
    "model = get_model(\n",
    "        config=cfg.model, data_info=lookups.data_info, text_encoder=text_encoder, label_transform = label_transform\n",
    "    )\n",
    "model.to(device)\n",
    "model_weights = torch.load(model_checkpoints/\"best_model.pt\", map_location=device)\n",
    "model.load_state_dict(model_weights['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "def prepare_inputs(text, text_transform, chunk_size):\n",
    "    tokenized_text = text_transform.transform(text)\n",
    "    token_ids, attention_mask = tokenized_text.values()\n",
    "    data = text_transform.seq2batch(token_ids, chunk_size=chunk_size)\n",
    "    attention_mask = text_transform.seq2batch(\n",
    "        attention_mask, chunk_size=chunk_size\n",
    "    )\n",
    "    return data, attention_mask\n",
    "\n",
    "def run_model(input_ids, attention_mask):\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        logits = torch.sigmoid(logits)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_df(logits):\n",
    "    # Define your tensor and JSON data\n",
    "    tensor_probs = logits[0]\n",
    "    target2index_path = model_checkpoints/'target2index.json'\n",
    "    with open(target2index_path, 'r') as json_file:\n",
    "        target2index = json.load(json_file)\n",
    "\n",
    "    # Create an empty DataFrame\n",
    "    df = pd.DataFrame(columns=target2index)\n",
    "\n",
    "    # Populate the DataFrame with probabilities\n",
    "    data_to_append = {}\n",
    "\n",
    "    for target, index in target2index.items():\n",
    "        probability = tensor_probs[index].item()\n",
    "        data_to_append[str(target)] = probability\n",
    "    new_record = pd.DataFrame([data_to_append])\n",
    "\n",
    "    return pd.concat([df, new_record], ignore_index=True)\n",
    "\n",
    "def select_top_k(k, df):\n",
    "    result_df_values = pd.DataFrame()\n",
    "\n",
    "    #create columns \n",
    "    for i in range(k):\n",
    "        result_df_values['top{}_column'.format(i+1)] = None\n",
    "        result_df_values['top{}_value'.format(i+1)] = None\n",
    "    \n",
    "    #set values to the new columns\n",
    "    for i  in range(len(df)):\n",
    "        top_k = df.iloc[i].sort_values(ascending= False)[:k]\n",
    "        keys = top_k.index\n",
    "        values = top_k.values\n",
    "        \n",
    "        keys_values = [item for pair in zip(keys, values) for item in pair]\n",
    "    \n",
    "        result_df_values.loc[i] = keys_values\n",
    "\n",
    "    return result_df_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get raw results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0002, 0.0002, 0.0005,  ..., 0.0010, 0.0001, 0.0002]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The patient underwent surgery on his right eye. Carcinoma of circumference 5mm found by biopsy. No other trauma detected expect an ankle profound wound. \"\n",
    "input_ids, attention_mask = prepare_inputs(text, text_transform, cfg.dataset.configs.chunk_size)\n",
    "run_model(input_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top1_column</th>\n",
       "      <th>top1_value</th>\n",
       "      <th>top2_column</th>\n",
       "      <th>top2_value</th>\n",
       "      <th>top3_column</th>\n",
       "      <th>top3_value</th>\n",
       "      <th>top4_column</th>\n",
       "      <th>top4_value</th>\n",
       "      <th>top5_column</th>\n",
       "      <th>top5_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99204</td>\n",
       "      <td>0.497726</td>\n",
       "      <td>97010</td>\n",
       "      <td>0.176998</td>\n",
       "      <td>99291</td>\n",
       "      <td>0.074879</td>\n",
       "      <td>99284</td>\n",
       "      <td>0.063306</td>\n",
       "      <td>99232</td>\n",
       "      <td>0.041571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  top1_column  top1_value top2_column  top2_value top3_column  top3_value  \\\n",
       "0       99204    0.497726       97010    0.176998       99291    0.074879   \n",
       "\n",
       "  top4_column  top4_value top5_column  top5_value  \n",
       "0       99284    0.063306       99232    0.041571  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df= logits_to_df(logits)\n",
    "select_top_k(k, result_df)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "871fb798708bc838ff59fced721021478b983a1108d0bec8499998232f12f3e6"
  },
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
