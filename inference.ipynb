{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from rich.pretty import pprint\n",
    "\n",
    "from src.data.data_pipeline import data_pipeline\n",
    "from src.factories import (\n",
    "    get_callbacks,\n",
    "    get_dataloaders,\n",
    "    get_datasets,\n",
    "    get_lookups,\n",
    "    get_lr_scheduler,\n",
    "    get_metric_collections,\n",
    "    get_model,\n",
    "    get_optimizer,\n",
    "    get_text_encoder,\n",
    "    get_transform,\n",
    ")\n",
    "from src.trainer.trainer import Trainer\n",
    "from src.utils.seed import set_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters for inference ###\n",
    "model_to_load = 'mimic_axa_cpt_hierarchical_short'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makes all necessary imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set directory \n",
    "dir_all_models = Path('files')\n",
    "model_checkpoints = dir_all_models/model_to_load\n",
    "\n",
    "#load config file\n",
    "cfg = OmegaConf.load(model_checkpoints/'config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Device: cpu'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Device: cpu'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'CUDA_VISIBLE_DEVICES: 0'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'CUDA_VISIBLE_DEVICES: 0'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if CUDA_VISIBLE_DEVICES is set\n",
    "if \"CUDA_VISIBLE_DEVICES\" not in os.environ:\n",
    "    if cfg.gpu != -1 and cfg.gpu is not None and cfg.gpu != \"\":\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = (\n",
    "            \",\".join([str(gpu) for gpu in cfg.gpu])\n",
    "            if isinstance(cfg.gpu, list)\n",
    "            else str(cfg.gpu)\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pprint(f\"Device: {device}\")\n",
    "pprint(f\"CUDA_VISIBLE_DEVICES: {os.environ['CUDA_VISIBLE_DEVICES']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transforming text... <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n",
       "Transforming text... <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span></pre>\n"
      ],
      "text/plain": [
       "\r\u001b[2KTransforming text... \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n",
       "Transforming text... \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[?25h"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data_pipeline(config=cfg.data)\n",
    "\n",
    "text_encoder = get_text_encoder(\n",
    "    config=cfg.text_encoder, data_dir=cfg.data.dir, texts=data.get_train_documents\n",
    ") #not needed\n",
    "label_transform = get_transform(\n",
    "    config=cfg.label_transform,\n",
    "    targets=data.all_targets,\n",
    "    load_transform_path=cfg.load_model,\n",
    ") #not needed\n",
    "text_transform = get_transform(\n",
    "    config=cfg.text_transform,\n",
    "    texts=data.get_train_documents,\n",
    "    text_encoder=text_encoder,\n",
    "    load_transform_path=cfg.load_model,\n",
    ")\n",
    "data.truncate_text(cfg.data.max_length) #not needed\n",
    "data.transform_text(text_transform.batch_transform) #not needed\n",
    "\n",
    "lookups = get_lookups(\n",
    "    config=cfg.lookup,\n",
    "    data=data,\n",
    "    label_transform=label_transform,\n",
    "    text_transform=text_transform,\n",
    ")\n",
    "\n",
    "model = get_model(\n",
    "        config=cfg.model, data_info=lookups.data_info, text_encoder=text_encoder, label_transform = label_transform\n",
    "    )\n",
    "model.to(device)\n",
    "model_weights = torch.load(model_checkpoints/\"best_model.pt\", map_location=device)\n",
    "model.load_state_dict(model_weights['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "def prepare_inputs(tokenized_text, text_transform, chunk_size):\n",
    "    token_ids, attention_mask = tokenized_text.values()\n",
    "    data = text_transform.seq2batch(token_ids, chunk_size=chunk_size)\n",
    "    attention_mask = text_transform.seq2batch(\n",
    "        attention_mask, chunk_size=chunk_size\n",
    "    )\n",
    "    return data, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The patient underwent surgery on his right eye. Carcinoma of circumference 5mm found by biopsy. No other trauma detected expect an ankle profound wound. \"\n",
    "tokenized_text = text_transform.transform(text)\n",
    "input_ids, attention_mask = prepare_inputs(tokenized_text, text_transform, cfg.dataset.configs.chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(input_ids, attention_mask)\n",
    "    logits = torch.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your tensor and JSON data\n",
    "tensor_probs = logits[0]\n",
    "target2index_path = model_checkpoints/'target2index.json'\n",
    "with open(target2index_path, 'r') as json_file:\n",
    "    target2index = json.load(json_file)\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame(columns=target2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the DataFrame with probabilities\n",
    "data_to_append = {}\n",
    "\n",
    "for target, index in target2index.items():\n",
    "    probability = tensor_probs[index].item()\n",
    "    data_to_append[str(target)] = probability\n",
    "new_record = pd.DataFrame([data_to_append])\n",
    "\n",
    "df = pd.concat([df, new_record], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPT predicted: 99291 Confidence 0.218035027384758\n"
     ]
    }
   ],
   "source": [
    "row_index = 0\n",
    "max_column = df.iloc[row_index].idxmax()\n",
    "confidence = df.iloc[row_index].max()\n",
    "print(f'CPT predicted: {max_column} Confidence {confidence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "871fb798708bc838ff59fced721021478b983a1108d0bec8499998232f12f3e6"
  },
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
